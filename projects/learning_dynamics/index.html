<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>dynamics | Suraj Anand</title> <meta name="author" content="Suraj Anand"> <meta name="description" content="learning dynamics in MLMs"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?505194d008ab58abcc3c0db57c2ae876"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://surajk610.github.io/projects/learning_dynamics/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Suraj Anand</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">dynamics</h1> <p class="post-description">learning dynamics in MLMs</p> </header> <article> <p>This is work that was completed with Jack Merullo and Michael Lepori on route to <a href="https://surajk610.github.io/assets/pdf/Dual_Process_Learning_Con.pdf">publication</a>. It was conduected at the Brown University Lunar Lab under supervision of Ellie Pavlick.</p> <h1 id="developmental-narrative-of-syntax-in-mlms">Developmental Narrative of Syntax in MLMs</h1> <p><em>Discovering the “push-down effect”: how syntactic knowledge migrates from late to early layers during training, and what this reveals about in-context vs. in-weights learning strategies in masked language models</em></p> <h2 id="where-does-grammar-live-in-mlms">Where Does Grammar Live in MLMs?</h2> <p>When BERT processes the sentence “I will mail the letter,” how does it know that “mail” is functioning as a verb rather than a noun? Previous research has shown that language models develop sophisticated syntactic understanding, but a fundamental question remained unanswered: <strong>How do these representations develop during training?</strong></p> <p>Our research reveals a surprising phenomenon we call the <strong>“push-down effect”</strong>: syntactic information initially appears in later layers of the network but gradually migrates to earlier layers as training progresses. This migration tells a deeper story about how language models balance two competing strategies for understanding language.</p> <h2 id="two-strategies-for-understanding-language">Two Strategies for Understanding Language</h2> <p>Language models can represent syntactic information through two fundamentally different approaches:</p> <h3 id="in-context-learning-the-algorithmic-approach">In-Context Learning: The Algorithmic Approach</h3> <ul> <li> <strong>Strategy</strong>: Derive part-of-speech information from surrounding context</li> <li> <strong>Example</strong>: “mail” after “will” → must be a verb</li> <li> <strong>Advantage</strong>: Handles ambiguous words flexibly</li> <li> <strong>Location</strong>: Typically requires deeper network layers for contextual reasoning</li> </ul> <h3 id="in-weights-learning-the-memorization-approach">In-Weights Learning: The Memorization Approach</h3> <ul> <li> <strong>Strategy</strong>: Encode part-of-speech information directly in word embeddings</li> <li> <strong>Example</strong>: “sofa” → almost always a noun, store this in the embedding</li> <li> <strong>Advantage</strong>: Fast, direct lookup for unambiguous words</li> <li> <strong>Location</strong>: Can be accessed from shallow network layers</li> </ul> <p><strong>The Central Question</strong>: When and why do models choose one strategy over the other?</p> <h2 id="discovering-the-push-down-effect">Discovering the Push-Down Effect</h2> <p>We analyzed the training dynamics of MultiBERT models using <strong>linear probing</strong>—training simple classifiers to extract syntactic information from different layers at various training checkpoints.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/probing-process-480.webp 480w, /assets/img/learning_dynamics/probing-process-800.webp 800w, /assets/img/learning_dynamics/probing-process-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/probing-process.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="probing process" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Probing setup diagram showing how we test syntactic tasks across layer and training step axes </div> <p><strong>Syntactic Tasks Studied</strong>:</p> <ul> <li> <strong>Part-of-speech tagging</strong> (coarse and fine-grained)</li> <li><strong>Named entity recognition</strong></li> <li><strong>Dependency parsing</strong></li> <li> <strong>Phrase boundaries</strong> (start/end detection)</li> <li> <strong>Parse tree structure</strong> (depth and distance)</li> </ul> <h3 id="the-striking-pattern">The Striking Pattern</h3> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/syntax_easy-480.webp 480w, /assets/img/learning_dynamics/syntax_easy-800.webp 800w, /assets/img/learning_dynamics/syntax_easy-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/syntax_easy.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntax_easy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/syntax_hard-480.webp 480w, /assets/img/learning_dynamics/syntax_hard-800.webp 800w, /assets/img/learning_dynamics/syntax_hard-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/syntax_hard.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntax_hard" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Probing Results measured across Layer vs. Step for MultiBERT Seed 0. Results are consistent across seeds. Top is easier syntactic tasks and bottom is more difficult tasks. </div> <p><strong>What we observed</strong>:</p> <ul> <li> <strong>Early training</strong>: Syntactic information only accessible in later layers (8-12)</li> <li> <strong>Mid training</strong>: Information becomes available in middle layers (4-8)</li> <li> <strong>Late training</strong>: Full syntactic knowledge accessible in early layers (1-3)</li> </ul> <p><strong>Two distinct regions emerged</strong>:</p> <ol> <li> <strong>Upper triangle</strong>: High accuracy, low variance (successful syntactic extraction)</li> <li> <strong>Lower triangle</strong>: Poor performance (information not yet available at that layer/time)</li> </ol> <h3 id="task-specific-migration-timing">Task-Specific Migration Timing</h3> <p>Different syntactic properties “pushed down” at different rates:</p> <p><strong>Migration Order</strong> (fastest to slowest):</p> <ol> <li> <strong>Named Entity Recognition</strong> → Quick migration to early layers</li> <li> <strong>Phrase boundaries</strong> → Moderate migration speed</li> <li> <strong>Part-of-speech tagging</strong> → Steady migration</li> <li> <strong>Dependency parsing</strong> → Slower migration</li> <li> <strong>Parse tree depth/distance</strong> → Remained in deeper layers</li> </ol> <p><strong>Key Insight</strong>: Simpler syntactic properties migrated earlier, while complex structural relationships required deeper processing throughout training.</p> <h2 id="a-synthetic-setup">A Synthetic Setup</h2> <p>To understand what drives the push-down effect, we designed a controlled synthetic task that captures the essence of part-of-speech disambiguation.</p> <h3 id="task-design">Task Design</h3> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/synthetic_task-480.webp 480w, /assets/img/learning_dynamics/synthetic_task-800.webp 800w, /assets/img/learning_dynamics/synthetic_task-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/synthetic_task.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="synthetic_task" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Synthetic task diagram showing sequence patterns </div> <p><strong>Grammar Structure</strong>:</p> <ul> <li> <strong>Sequence types</strong>: <code class="language-plaintext highlighter-rouge">&lt;noun&gt; cop &lt;adj&gt;</code> or <code class="language-plaintext highlighter-rouge">cop &lt;adj&gt; &lt;noun&gt;</code> (50% probability each)</li> <li> <strong>Query</strong>: Ask for specific <code class="language-plaintext highlighter-rouge">&lt;noun&gt;</code> or <code class="language-plaintext highlighter-rouge">&lt;adj&gt;</code> token</li> <li> <strong>Challenge</strong>: Model must determine POS of query token to generate correct pattern</li> </ul> <p><strong>Two Learning Strategies Available</strong>:</p> <ol> <li> <strong>Algorithmic</strong>: Use position relative to “cop” (copula) to determine POS</li> <li> <strong>Memorization</strong>: Encode which tokens are nouns vs. adjectives in embeddings</li> </ol> <h3 id="critical-variables-tested">Critical Variables Tested</h3> <ol> <li> <strong>Distribution Type</strong>: Uniform vs. Zipfian (natural language-like)</li> <li> <strong>Vocabulary Size</strong>: 100 to 20,000 tokens</li> <li> <strong>Ambiguity Level</strong>: 0% to 50% chance tokens can switch roles</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/syntactic_zipfian-480.webp 480w, /assets/img/learning_dynamics/syntactic_zipfian-800.webp 800w, /assets/img/learning_dynamics/syntactic_zipfian-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/syntactic_zipfian.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntactic_zipfian" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-6 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/syntactic_uniform-480.webp 480w, /assets/img/learning_dynamics/syntactic_uniform-800.webp 800w, /assets/img/learning_dynamics/syntactic_uniform-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/syntactic_uniform.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntactic_uniform" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Feature representations originate in higher layers and layer arise in lower layers in the synthetic task for Zipfian distributions, not for Uniform. </div> <h4 id="distribution-drives-strategy-selection">Distribution Drives Strategy Selection</h4> <p><strong>Zipfian Distribution</strong> (like natural language):</p> <ul> <li> <strong>Push-down effect observed</strong>: Information migrated from late to early layers</li> <li> <strong>Strategy transition</strong>: Started with in-context learning, moved to memorization</li> <li> <strong>Critical insight</strong>: Long tail of rare words forced development of algorithmic strategy</li> </ul> <p><strong>Uniform Distribution</strong>:</p> <ul> <li> <strong>No push-down effect</strong>: Information appeared in early layers immediately</li> <li> <strong>Pure memorization</strong>: Model relied entirely on in-weights strategy</li> <li> <strong>No algorithmic development</strong>: No pressure to develop contextual reasoning</li> </ul> <h4 id="the-role-of-ambiguity">The Role of Ambiguity</h4> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/zipf_amb=0.00_vs=20000_a=1.5-480.webp 480w, /assets/img/learning_dynamics/zipf_amb=0.00_vs=20000_a=1.5-800.webp 800w, /assets/img/learning_dynamics/zipf_amb=0.00_vs=20000_a=1.5-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/zipf_amb=0.00_vs=20000_a=1.5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntactic_zipfian" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/learning_dynamics/zipf_amb=0.10_vs=20000_a=1.5-480.webp 480w, /assets/img/learning_dynamics/zipf_amb=0.10_vs=20000_a=1.5-800.webp 800w, /assets/img/learning_dynamics/zipf_amb=0.10_vs=20000_a=1.5-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/learning_dynamics/zipf_amb=0.10_vs=20000_a=1.5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="syntactic_uniform" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Effect of ambiguity on learning strategies. (Left is p=0.00 ambiguous POS, Right is p=0.10 ambiguous POS). Validation and tail probing with differing probabilities of ambiguous POS (i.e. noun being chosen from adjective set and vice versa); tokens are chosen from a Zipf distribution with $\alpha=1.001$ and a vocab size of 10,000. </div> <p><strong>No Ambiguity (0%)</strong>:</p> <ul> <li>Model could rely purely on memorization</li> <li>Switch accuracy remained low (memorization successful)</li> </ul> <p><strong>Any Ambiguity (≥1%)</strong>:</p> <ul> <li> <strong>Forced algorithmic strategy</strong>: Model had to use context when tokens could switch roles</li> <li> <strong>Switch accuracy matched validation accuracy</strong>: Clear evidence of in-context learning</li> <li> <strong>Surprising finding</strong>: Even with algorithmic strategy, POS information still stored in embeddings</li> </ul> <h3 id="natural-language-statistics-drive-algorithmic-development">Natural Language Statistics Drive Algorithmic Development</h3> <p><strong>The Zipfian Effect</strong>: Natural language’s long-tailed distribution (many rare words) forces models to develop in-context strategies because memorization alone cannot handle the full vocabulary.</p> <p><strong>Training Progression</strong>:</p> <ol> <li> <strong>Early</strong>: Learn frequent words through memorization</li> <li> <strong>Middle</strong>: Develop algorithmic strategy for rare words</li> <li> <strong>Late</strong>: “Distill” algorithmic knowledge into early layers for efficiency</li> </ol> <h3 id="memorization-and-contextualization-coexist">Memorization and Contextualization Coexist</h3> <p><strong>False Dichotomy</strong>: The field often frames memorization vs. generalization as competing forces, but our results show they’re <strong>complementary strategies</strong>:</p> <ul> <li> <strong>Memorization</strong>: Handles frequent, unambiguous cases efficiently</li> <li> <strong>Contextualization</strong>: Handles rare and ambiguous cases accurately</li> <li> <strong>Integration</strong>: Models use both strategies simultaneously</li> </ul> <h3 id="architecture-efficiency-through-knowledge-distillation">Architecture Efficiency Through Knowledge Distillation</h3> <p><strong>The Push-Down Mechanism</strong>: Later layers develop algorithmic strategies, then “teach” earlier layers to encode this knowledge more efficiently.</p> <p><strong>Computational Advantage</strong>:</p> <ul> <li> <strong>Deep processing</strong>: Available when needed for complex cases</li> <li> <strong>Shallow access</strong>: Quick lookup for common cases</li> <li> <strong>Best of both worlds</strong>: Flexibility with efficiency</li> </ul> <h3 id="progress-measures-for-strategy-detection">Progress Measures for Strategy Detection</h3> <p><strong>Novel Metrics</strong>:</p> <ul> <li> <strong>Switch Accuracy</strong>: Test model on swapped noun/adjective roles to detect algorithmic vs. memorization strategies</li> <li> <strong>Tail Accuracy</strong>: Evaluate performance on rare tokens to assess generalization</li> <li> <strong>Unseen Token Performance</strong>: Test completely novel tokens to isolate algorithmic capability</li> </ul> <p><strong>Causal Understanding</strong>: These measures allowed us to not just observe strategy changes but understand <strong>why</strong> they occurred.</p> <hr> <h2 id="future-research">Future Research</h2> <p>These are just initial steps. Some interesting questions that would help validate this study are here.</p> <ol> <li>Scaling to Modern Models</li> <li>Cross-Linguistic Generalization</li> <li>Applications to Model Development (e.g. Use syntactic development as training completion signal, identify when models develop problematic learning strategies)</li> </ol> <h2 id="conclusion">Conclusion</h2> <p>Our research reveals that language models don’t simply “learn syntax”—they develop increasingly sophisticated strategies for representing and accessing syntactic information. The push-down effect demonstrates a previously unknown training dynamic where <strong>models actively reorganize their knowledge</strong> to balance computational efficiency with representational flexibility.</p> <p><strong>Key Takeaways</strong>:</p> <ol> <li> <strong>Syntactic knowledge migrates</strong> from deep to shallow layers during training</li> <li> <strong>Natural language statistics</strong> drive the development of algorithmic reasoning strategies</li> <li> <strong>Memorization and contextualization</strong> are complementary, not competing approaches</li> <li> <strong>Training dynamics</strong> provide crucial insights beyond static model analysis</li> </ol> <p><strong>Broader Impact</strong>: Understanding how models develop linguistic knowledge—rather than just what knowledge they possess—opens new avenues for building more efficient, interpretable, and robust language models.</p> <p>The “push-down effect” reveals fundamental principles about how neural networks can efficiently organize knowledge, suggesting that the most effective AI systems may be those that, like our models, learn to balance multiple complementary strategies for understanding their domain.</p> <h2 id="references">References</h2> <p>Please refer to <a href="https://surajk610.github.io/assets/pdf/Dual_Process_Learning_Con.pdf">publication</a> for references.</p> <hr> <p><em>This research provides a developmental perspective on language model interpretability, showing that the journey of learning is as revealing as the destination. The complete experimental framework and findings offer new tools for understanding and improving language model training.</em></p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Suraj Anand. Thank you for visiting. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>