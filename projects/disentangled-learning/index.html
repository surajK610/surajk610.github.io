<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>disentangled | Suraj Anand</title> <meta name="author" content="Suraj Anand"> <meta name="description" content="a novel algorithm for disentangled learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?505194d008ab58abcc3c0db57c2ae876"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://surajk610.github.io/projects/disentangled-learning/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Suraj Anand</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">disentangled</h1> <p class="post-description">a novel algorithm for disentangled learning</p> </header> <article> <h1 id="disentangling-causal-mechanisms">Disentangling Causal Mechanisms</h1> <p><em>How we built disentangled representations by explicitly partitioning latent spaces and obstructing unwanted correlations</em></p> <h2 id="when-ai-learns-the-wrong-things">When AI Learns the Wrong Things</h2> <p>Imagine training an AI model to recognize cows, only to discover it’s actually learned to identify green, grassy backgrounds instead of the animals themselves. Show it a car parked on a grassy field, and it confidently predicts “cow.” This isn’t just a hypothetical—it’s a real problem plaguing modern deep neural networks.</p> <p><strong>The core issue</strong>: Deep neural networks tend to entangle features in their internal representations, leading to:</p> <ul> <li> <strong>Spurious correlations</strong>: Models learn shortcuts that don’t generalize</li> <li> <strong>Black-box behavior</strong>: Predictions become uninterpretable</li> <li> <strong>Non-compositional representations</strong>: Features can’t be independently manipulated</li> <li> <strong>Poor generalization</strong>: Models fail on out-of-distribution data</li> </ul> <p>This is where <strong>disentangled representation learning</strong> comes in—the quest to build AI systems that learn independent, interpretable features that mirror how we naturally understand the world.</p> <h2 id="projection-based-disentanglement">Projection-Based Disentanglement</h2> <p>Most existing approaches to disentanglement, like β-VAEs and InfoGAN, rely on implicit constraints and information-theoretic objectives. We took a different path: <strong>what if we explicitly force independent mechanisms into separate parts of the latent space?</strong></p> <p>Our key insight: <strong>Use adversarial projection to actively obstruct unwanted correlations while preserving wanted information.</strong></p> <h3 id="r-lace">R-LACE</h3> <p>Our method builds on <strong>Relaxed Linear Adversarial Concept Erasure (R-LACE)</strong>, originally designed for debiasing word embeddings. R-LACE works by solving a minimax game:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>min max Σ ℓ(yₙ, g⁻¹(θᵀ P xₙ))
 θ   P
</code></pre></div></div> <p>Where:</p> <ul> <li> <strong>P</strong> is an orthogonal projection matrix that removes unwanted information</li> <li> <strong>θ</strong> represents classifier parameters trying to recover that information</li> <li>The game finds the optimal projection that maximally confuses classifiers</li> </ul> <p><strong>Our contribution</strong>: We adapted this adversarial projection approach to enforce disentanglement during autoencoder training.</p> <h2 id="the-method-partitioned-latent-spaces-with-adversarial-constraints">The Method: Partitioned Latent Spaces with Adversarial Constraints</h2> <h3 id="experimental-setup-colored-mnist">Experimental Setup: Colored MNIST</h3> <p>To demonstrate our approach, we designed a controlled experiment using <strong>Colored MNIST</strong>:</p> <ul> <li> <strong>Dataset</strong>: MNIST digits randomly colored red, green, or blue</li> <li> <strong>Goal</strong>: Partition latent space to encode digit and color independently</li> <li> <strong>Challenge</strong>: Prevent the model from learning digit-color correlations</li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/colored_mnist-480.webp 480w, /assets/img/disentangled/colored_mnist-800.webp 800w, /assets/img/disentangled/colored_mnist-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/colored_mnist.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="nsight systems" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Examples from the Colored MNIST dataset showing digits 0-9 in red, green, and blue colors </div> <h3 id="architecture-the-disentangled-autoencoder">Architecture: The Disentangled Autoencoder</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">RLACE_AE</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">d</span><span class="o">=</span><span class="mi">6</span><span class="p">):</span>
        <span class="c1"># Standard autoencoder components
</span>        <span class="n">self</span><span class="p">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">encoded_space_dim</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">encoded_space_dim</span><span class="o">=</span><span class="n">d</span><span class="p">)</span>
        
        <span class="c1"># Projection matrices for each latent partition
</span>        <span class="n">self</span><span class="p">.</span><span class="n">P1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Remove color info
</span>        <span class="n">self</span><span class="p">.</span><span class="n">P2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Remove digit info
</span></code></pre></div></div> <p>Our architecture implements a <strong>partitioned latent space</strong> approach:</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/model_arch-480.webp 480w, /assets/img/disentangled/model_arch-800.webp 800w, /assets/img/disentangled/model_arch-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/model_arch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="nsight systems" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Architecture diagram showing the disentangled autoencoder with R-LACE </div> <ol> <li> <strong>Encoder</strong>: Maps images to d-dimensional latent vectors</li> <li> <strong>Partition</strong>: Split latent space into two d/2-dimensional subspaces</li> <li> <strong>Projection</strong>: Apply R-LACE to each partition: <ul> <li> <strong>Partition 1</strong>: Remove color information → pure digit encoding</li> <li> <strong>Partition 2</strong>: Remove digit information → pure color encoding</li> </ul> </li> <li> <strong>Decoder</strong>: Reconstruct images from projected latent representations</li> </ol> <h3 id="training-process-alternating-optimization">Training Process: Alternating Optimization</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">solve_adv_game</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="n">o_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">a_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">o_step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">o_epochs</span><span class="p">):</span>
        <span class="c1"># Train autoencoder for a_epochs with current projections
</span>        <span class="k">for</span> <span class="n">a_step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">a_epochs</span><span class="p">):</span>
            <span class="n">train_ae_loss</span> <span class="o">=</span> <span class="nf">train_epoch_with_projection</span><span class="p">(</span>
                <span class="n">self</span><span class="p">.</span><span class="n">encoder</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">decoder</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">P1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">P2</span><span class="p">,</span> 
                <span class="n">dataloader</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">MSELoss</span><span class="p">(),</span> <span class="n">optimizer</span>
            <span class="p">)</span>
        
        <span class="c1"># Update projections using R-LACE
</span>        <span class="n">X</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">encoder</span><span class="p">(</span><span class="n">batch_data</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span>
        <span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">d</span><span class="o">//</span><span class="mi">2</span><span class="p">:]</span>  <span class="c1"># Partition latent space
</span>        
        <span class="c1"># Solve adversarial games for each partition
</span>        <span class="n">rlace_output1</span> <span class="o">=</span> <span class="nf">rlace</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">color_labels</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">rlace_output2</span> <span class="o">=</span> <span class="nf">rlace</span><span class="p">(</span><span class="n">X2</span><span class="p">,</span> <span class="n">digit_labels</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">P1</span> <span class="o">=</span> <span class="n">rlace_output1</span><span class="p">.</span><span class="n">best_P</span>
        <span class="n">self</span><span class="p">.</span><span class="n">P2</span> <span class="o">=</span> <span class="n">rlace_output2</span><span class="p">.</span><span class="n">best_P</span>
</code></pre></div></div> <p><strong>Key innovation</strong>: The alternating optimization between autoencoder training and projection matrix updates creates an <strong>information bottleneck</strong> that forces independent mechanisms into separate latent dimensions.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/obstruction_vis-480.webp 480w, /assets/img/disentangled/obstruction_vis-800.webp 800w, /assets/img/disentangled/obstruction_vis-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/obstruction_vis.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="nsight systems" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Illustration of R-LACE projection concept </div> <h2 id="results-achieving-true-disentanglement">Results: Achieving True Disentanglement</h2> <p>Our experiments revealed clear evidence of successful disentanglement:</p> <table> <thead> <tr> <th>Latent Partition Size</th> <th>Reconstruction Loss</th> <th>Digit Accuracy (Full)</th> <th>Color Accuracy (Full)</th> </tr> </thead> <tbody> <tr> <td>n=1</td> <td>0.03</td> <td>0.55 (random)</td> <td>0.33 (random)</td> </tr> <tr> <td>n=2</td> <td>0.02</td> <td>0.51</td> <td>0.95</td> </tr> <tr> <td>n=3</td> <td>0.009</td> <td>0.89</td> <td>0.92</td> </tr> <tr> <td>n=5</td> <td>0.006</td> <td>0.89</td> <td>0.97</td> </tr> </tbody> </table> <p><strong>Critical insight</strong>: At least 3 dimensions per partition are needed for effective disentanglement. With n=1, R-LACE removes too much information; with n≥3, we achieve both good reconstruction and strong disentanglement.</p> <h3 id="disentanglement-verification">Disentanglement Verification</h3> <p>To verify true disentanglement, we trained classifiers on each projected latent partition:</p> <table> <thead> <tr> <th>Partition Size</th> <th>Digit Encoding → Digit Acc</th> <th>Digit Encoding → Color Acc</th> <th>Color Encoding → Digit Acc</th> <th>Color Encoding → Color Acc</th> </tr> </thead> <tbody> <tr> <td>n=3</td> <td><strong>0.42</strong></td> <td>0.38 (near random)</td> <td>0.32 (near random)</td> <td><strong>0.94</strong></td> </tr> <tr> <td>n=5</td> <td><strong>0.74</strong></td> <td>0.48</td> <td>0.39</td> <td><strong>0.99</strong></td> </tr> </tbody> </table> <p><strong>Success criteria</strong>:</p> <ul> <li>High accuracy when predicting the “corresponding” feature (0.74 digit, 0.99 color)</li> <li>Near-random accuracy when predicting the “opposite” feature (0.39-0.48)</li> </ul> <h3 id="visual-evidence-latent-space-visualization">Visual Evidence: Latent Space Visualization</h3> <p>The most compelling evidence comes from visualizing the learned latent spaces:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/vanilla_latent-480.webp 480w, /assets/img/disentangled/vanilla_latent-800.webp 800w, /assets/img/disentangled/vanilla_latent-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/vanilla_latent.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="vanilla_latent" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/disentangled_digits-480.webp 480w, /assets/img/disentangled/disentangled_digits-800.webp 800w, /assets/img/disentangled/disentangled_digits-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/disentangled_digits.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="disentangled_digits" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset=" /assets/img/disentangled/disentangled_color-480.webp 480w, /assets/img/disentangled/disentangled_color-800.webp 800w, /assets/img/disentangled/disentangled_color-1400.webp 1400w, " sizes="95vw" type="image/webp"></source> <img src="/assets/img/disentangled/disentangled_color.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="disentangled_color" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Latent space visualizations showing disentanglement: (a) vanilla autoencoder, (b) digit encoding dimensions, (c) color encoding dimensions </div> <p><strong>Before Disentanglement (Vanilla Autoencoder)</strong>:</p> <ul> <li>Digit and color information completely entangled</li> <li>No clear separation between concepts</li> </ul> <p><strong>After Disentanglement</strong>:</p> <ul> <li> <strong>Digit Partition</strong>: Clear digit clusters, no color separation</li> <li> <strong>Color Partition</strong>: Clear color clusters, digits highly entangled</li> </ul> <p>This visual separation confirms that our method successfully isolates independent causal mechanisms.</p> <h3 id="the-mathematics-of-adversarial-projection">The Mathematics of Adversarial Projection</h3> <p>R-LACE solves a constrained minimax game to find optimal projection matrices:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>P ∈ Pₖ ⟺ P = I_D - W^T W,  W ∈ R^(K×D), WW^T = Iₖ
</code></pre></div></div> <p>Where <strong>P</strong> projects onto the orthogonal complement of a k-dimensional bias subspace. The projection <strong>neutralizes</strong> unwanted correlations while preserving other information.</p> <h3 id="information-bottleneck-interpretation">Information Bottleneck Interpretation</h3> <p>Our alternating training creates an <strong>explicit information bottleneck</strong>:</p> <ol> <li> <strong>Autoencoder loss</strong> pressures the model to preserve all information needed for reconstruction</li> <li> <strong>R-LACE projection</strong> removes specific correlations between partitions</li> <li> <strong>Competition</strong> forces the model to encode different concepts in different partitions</li> </ol> <p>This is fundamentally different from implicit approaches like β-VAE, which rely on regularization to encourage disentanglement.</p> <h3 id="advantages-over-existing-methods">Advantages Over Existing Methods</h3> <table> <thead> <tr> <th>Method</th> <th>Explicit Mapping</th> <th>Known Structure</th> <th>Interpretability</th> <th>Performance</th> </tr> </thead> <tbody> <tr> <td>β-VAE</td> <td>No</td> <td>No</td> <td>Moderate</td> <td>Good</td> </tr> <tr> <td>InfoGAN</td> <td>No</td> <td>No</td> <td>Good</td> <td>Moderate</td> </tr> <tr> <td><strong>Our Method</strong></td> <td>Yes</td> <td>Yes</td> <td>Excellent</td> <td>Excellent</td> </tr> </tbody> </table> <p><strong>Key advantages</strong>:</p> <ul> <li> <strong>Explicit mapping</strong>: We know exactly which dimensions encode which features</li> <li> <strong>Principled approach</strong>: Based on solid theoretical foundations (adversarial projection)</li> <li> <strong>Flexible framework</strong>: Can be adapted to any number of known causal factors</li> </ul> <h2 id="limitations-and-future-directions">Limitations and Future Directions</h2> <ol> <li> <strong>Known causal structure required</strong>: Our method assumes you know the independent factors a priori</li> <li> <strong>Training stability</strong>: The alternating optimization can be unstable with poor hyperparameter choices</li> <li> <strong>Scalability</strong>: Tested only on simple datasets (Colored MNIST)</li> <li> <strong>Independence assumption</strong>: Requires truly independent generative factors</li> </ol> <p>While our approach shows promise in controlled settings, several fundamental challenges limit its real-world applicability:</p> <h4 id="the-superposition-problem">The Superposition Problem</h4> <p>Real neural networks exhibit <strong>superposition</strong> - the phenomenon where features are represented as linear combinations across many dimensions rather than being cleanly separated. As demonstrated in recent work on mechanistic interpretability, individual neurons often encode multiple concepts simultaneously, and individual concepts are distributed across multiple neurons. This creates several problems for our approach:</p> <ul> <li> <strong>Feature interference</strong>: When concepts naturally superpose, enforcing strict partitioning may damage both concepts</li> <li> <strong>Representation efficiency</strong>: Neural networks may achieve better compression by allowing controlled feature mixing</li> <li> <strong>Emergent representations</strong>: Some high-level concepts only emerge through combinations of lower-level features</li> </ul> <h4 id="unknown-intrinsic-dimensionality">Unknown Intrinsic Dimensionality</h4> <p>A major practical limitation is that we rarely know the <strong>intrinsic dimensionality</strong> of real generative factors:</p> <ul> <li> <strong>How many dimensions does “color” really need?</strong> In our Colored MNIST experiment, we assumed color could be encoded in d/2 dimensions, but real color spaces are complex</li> <li> <strong>What about hierarchical factors?</strong> Object identity might require 50 dimensions, while lighting might need 20, but we don’t know these numbers a priori</li> <li> <strong>Interaction effects</strong>: Some factors may require additional dimensions when they interact (e.g., how material appearance changes under different lighting)</li> </ul> <p><strong>Example failure case</strong>: If we allocate too few dimensions to a complex factor, R-LACE will successfully remove “unwanted” correlations, but the remaining space won’t be sufficient to represent the factor adequately.</p> <h4 id="the-generative-factor-discovery-problem">The Generative Factor Discovery Problem</h4> <p>Perhaps the most fundamental limitation: <strong>we typically don’t know what the true generative factors are</strong>:</p> <ul> <li> <strong>Natural images</strong>: What are the independent factors generating a photo? Object identity, pose, lighting, camera parameters, background, weather, time of day…?</li> <li> <strong>Language</strong>: Syntax, semantics, pragmatics, style, register, emotional content…?</li> <li> <strong>Medical data</strong>: Disease state, patient demographics, imaging modality, technical factors…?</li> </ul> <p>Our Colored MNIST example benefits from a <strong>perfectly controlled environment</strong> where we artificially created exactly two independent factors. Real-world data lacks this luxury.</p> <h4 id="computational-and-scalability-issues">Computational and Scalability Issues</h4> <p><strong>Memory complexity</strong>: As the number of factors grows, our approach requires:</p> <ul> <li>Separate projection matrices for each factor: O(k × d²/k) = O(d²) space</li> <li>Separate R-LACE optimization for each partition: O(k) computational overhead</li> <li>Joint optimization across all partitions: potentially exponential in the number of factors</li> </ul> <p><strong>Training instability</strong>: The alternating optimization can fail when:</p> <ul> <li>Factors are not truly independent (most real cases)</li> <li>Latent dimensions are insufficient</li> <li>Multiple factors compete for the same representational space</li> </ul> <h3 id="when-the-approach-breaks-down">When the Approach Breaks Down</h3> <p>Consider these realistic scenarios where our method would struggle:</p> <h4 id="scenario-1-medical-imaging">Scenario 1: Medical Imaging</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>

<span class="c1">#### Scenario 1: Natural Language
</span><span class="sb">``</span><span class="err">`</span><span class="n">python</span>
<span class="n">factors</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">syntax</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">semantics</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">style</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Reality:
# - Syntax and semantics are deeply intertwined
# - Style affects both syntax and semantic choices
# - Cultural context influences all factors
# - Individual word meanings depend on context
# - We can't cleanly separate these concepts
</span></code></pre></div></div> <h4 id="scenario-2-real-world-images">Scenario 2: Real-World Images</h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">factors</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">object_identity</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">pose</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">lighting</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">background</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Why this fails:
# - Object appearance changes dramatically with pose and lighting
# - Background affects object visibility and interpretation
# - Some objects are defined partly by their typical backgrounds
# - Pose space dimensionality varies dramatically by object type
</span></code></pre></div></div> <h3 id="the-fundamental-trade-off">The Fundamental Trade-off</h3> <p>Our approach reveals a <strong>fundamental tension</strong> in disentangled representation learning:</p> <p><strong>Perfect disentanglement</strong> ↔ <strong>Representational efficiency</strong></p> <ul> <li> <strong>Strict partitioning</strong> ensures interpretability but may waste representational capacity</li> <li> <strong>Allowing superposition</strong> enables efficient compression and simulation of higher dimensional networks but loses interpretability</li> <li> <strong>Real neural networks</strong> appear to prefer efficiency over interpretability</li> </ul> <p>This suggests that the goal of “perfect disentanglement” may be fundamentally at odds with how neural networks naturally want to represent information.</p> <h2 id="implementation-and-reproducibility">Implementation and Reproducibility</h2> <p>Our complete implementation is available on <a href="https://github.com/surajK610/disentangled-learning-by-projection" rel="external nofollow noopener" target="_blank">GitHub</a>, including:</p> <ul> <li> <strong>Dataset generation</strong>: Colored MNIST creation scripts</li> <li> <strong>Model architecture</strong>: Complete autoencoder with R-LACE integration</li> <li> <strong>Training pipeline</strong>: Alternating optimization implementation</li> <li> <strong>Evaluation metrics</strong>: Disentanglement quality assessment</li> <li> <strong>Visualization tools</strong>: Latent space plotting and reconstruction galleries</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Our work introduces a fundamentally new approach to disentangled representation learning that moves beyond implicit regularization to <strong>explicit structural constraints</strong>. By leveraging adversarial projection to obstruct unwanted correlations, we achieve:</p> <p><strong>True disentanglement</strong>: Independent factors in separate latent dimensions<br> <strong>Explicit mapping</strong>: Known correspondence between dimensions and concepts<br> <strong>Principled foundation</strong>: Based on solid theoretical understanding<br> <strong>Practical effectiveness</strong>: Demonstrated on concrete experimental tasks</p> <p><strong>Key insight</strong>: Sometimes the best way to learn independent representations is to actively fight against entanglement, rather than hoping regularization will encourage it. However, this approach may be fundamentally limited by the reality that natural data often exhibits meaningful entanglement and superposition.</p> <p>Still, we believe our work represents a step toward more <strong>interpretable and trustworthy AI systems</strong>. By explicitly partitioning causal mechanisms, we enable:</p> <h3 id="compositional-generation">Compositional Generation</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Mix and match independent factors
</span><span class="n">digit_encoding</span> <span class="o">=</span> <span class="nf">encode_digit</span><span class="p">(</span><span class="n">image_of_7</span><span class="p">)</span>
<span class="n">color_encoding</span> <span class="o">=</span> <span class="nf">encode_color</span><span class="p">(</span><span class="n">blue_image</span><span class="p">)</span>
<span class="n">new_image</span> <span class="o">=</span> <span class="nf">decode</span><span class="p">(</span><span class="nf">concat</span><span class="p">(</span><span class="n">digit_encoding</span><span class="p">,</span> <span class="n">color_encoding</span><span class="p">))</span>
<span class="c1"># Result: blue number 7
</span></code></pre></div></div> <h3 id="robust-domain-transfer">Robust Domain Transfer</h3> <ul> <li>Models with disentangled representations should generalize better to new color-digit combinations</li> <li>Less susceptible to spurious correlations in training data</li> </ul> <h3 id="interpretable-interventions">Interpretable Interventions</h3> <ul> <li>Modify specific attributes without affecting others</li> <li>Enable precise control over generated content</li> <li>Support counterfactual reasoning</li> </ul> <h3 id="looking-forward">Looking Forward</h3> <p>As AI systems become more complex and consequential, the ability to understand and control their internal representations becomes increasingly critical. Our projection-based approach provides a concrete step toward building AI systems that are not just powerful, but <strong>interpretable, controllable, and trustworthy</strong>.</p> <p>However, the practical limitations we’ve identified suggest that the path forward may require fundamentally different approaches. Rather than enforcing perfect disentanglement, future work might focus on <strong>controllable entanglement</strong> - systems that can flexibly adjust the degree of factor separation based on the task at hand.</p> <p>The marriage of causal structure knowledge with end-to-end neural optimization opens exciting possibilities, but the challenges of superposition, unknown dimensionality, and factor discovery remind us that the goal of truly disentangled AI remains an active area of research with significant unsolved problems.</p> <hr> <p><em>This research was conducted at Brown University’s Department of Computer Science with collaborator Neil Xu. The complete codebase, experimental data, and additional visualizations are available in our <a href="https://github.com/surajK610/disentangled-learning-by-projection" rel="external nofollow noopener" target="_blank">GitHub repository</a>.</em></p> <h2 id="technical-appendix">Technical Appendix</h2> <h3 id="r-lace-implementation-details">R-LACE Implementation Details</h3> <p><strong>Core Algorithm</strong>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rlace</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># Initialize with Spectral Attribute Removal
</span>    <span class="n">P</span> <span class="o">=</span> <span class="nf">sal_initialization</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="c1"># Train classifier on projected data
</span>        <span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="p">(</span><span class="n">I</span> <span class="o">-</span> <span class="n">P</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="c1"># Update projection to maximize classifier loss
</span>        <span class="n">P</span> <span class="o">=</span> <span class="nf">optimize_projection</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="nf">convergence_check</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">clf_loss</span><span class="p">):</span>
            <span class="k">break</span>
    
    <span class="k">return</span> <span class="nf">orthogonalize</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Convergence Criteria</strong>:</p> <ul> <li>Gradient norm threshold: 1e-2</li> <li>Loss improvement tolerance: 1e-2</li> <li>Maximum iterations: 100</li> </ul> <h3 id="evaluation-metrics">Evaluation Metrics</h3> <p><strong>Disentanglement Score</strong>:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DS = (Acc_corresponding - Acc_opposite) / Acc_corresponding
</code></pre></div></div> <p>Where:</p> <ul> <li>Acc_corresponding: Accuracy predicting correct factor from its partition</li> <li>Acc_opposite: Accuracy predicting wrong factor from partition</li> </ul> <p><strong>Perfect disentanglement</strong>: DS = 1.0<br> <strong>No disentanglement</strong>: DS = 0.0</p> <h3 id="references">References</h3> <p>Please see the <a href="https://surajk610.github.io/assets/pdf/Disentangling_Causal_Mechanisms_By_Obstructing_Classifiers.pdf">writeup</a> for the full references.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Suraj Anand. Thank you for visiting. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?07b8786bab9b4abe90d10e61f7d12ff7" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>